{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZKGhYYH2XuICMoKu8bweo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AqueeqAzam/supervised-learning/blob/main/supervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1Ô∏è‚É£ Regression (Predicting a Continuous Value)\n",
        "--\n",
        "Algorithm\tBest For\tExample Data\tData Type\n",
        "\n",
        "Linear Regression\tSimple relationships\tHouse Price ~ Area\tContinuous (Numerical)\n",
        "\n",
        "Multiple Linear Regression\tMultiple factors\tHouse Price ~ Area + Location + Bedrooms\tContinuous & Categorical\n",
        "\n",
        "Polynomial Regression\tCurved relationships\tSalary Growth Over Years\tContinuous (with Non-Linearity)\n",
        "\n",
        "Support Vector Regression (SVR)\tComplex relationships\tStock Market Trends\tContinuous (Non-Linear)\n",
        "\n",
        "k-NN Regression\tSmall datasets, local patterns\tPredicting car price based on similar models\tContinuous, Categorical\n"
      ],
      "metadata": {
        "id": "5-3yuIcCJM76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1Ô∏è‚É£ Simple Linear Regression\n",
        "üìå Use Case: Price (target) vs. Area (feature)\n",
        "\n",
        "üìå Best When: ‚úÖ There is a linear relationship between Price and Area. ‚úÖ You need a simple and interpretable model. ‚úÖ Dataset is small to medium-sized.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå The relationship between features is non-linear. ‚ùå There are multiple independent variables affecting the target.\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Real Estate Pricing (Zillow, Redfin, Realtor) ‚Üí Predicting home prices based on Area. Salary Estimation (HR & Job Market Analytics) ‚Üí Estimating salary based on years of experience."
      ],
      "metadata": {
        "id": "Ja08H6BfJDX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    'House_ID': [1, 2, 3],\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment'],\n",
        "    'Price': [500000, 750000, 600000],\n",
        "    'Construction_Date': ['2020-01-01', '2018-05-15', '2019-07-20'],\n",
        "    'Is_Active': [np.nan, False, True],\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\"],\n",
        "    'Area': [1200, 1500, 1300],\n",
        "    'Rating': [4, 5, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical feature 'Type' into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
        "\n",
        "# Impute missing values in 'Rating' with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Rating'] = imputer.fit_transform(df[['Rating']])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Area', 'Rating']]\n",
        "y = df['Price']\n",
        "\n",
        "# Train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict prices based on the given data\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Output predictions\n",
        "df['Predicted_Price'] = predictions\n",
        "df[['Price', 'Predicted_Price']]\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "# Regression equation coefficients\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Display results\n",
        "df['Predicted_Price'] = predictions\n",
        "print(f\"Regression Equation: Price = {intercept:.2f} + ({coefficients[0]:.2f} * Area) + ({coefficients[1]:.2f} * Rating)\")\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "df[['Price', 'Predicted_Price']]\n"
      ],
      "metadata": {
        "id": "zoJJIy74I_A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2Ô∏è‚É£ Multiple Linear Regression\n",
        "üìå Use Case: Price (target) vs. Area, Rating, Latitude, Longitude üìå Best When: ‚úÖ The target variable is influenced by multiple factors. ‚úÖ There is a linear relationship between features and Price.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå Features have high multicollinearity (strong correlation among independent variables). ‚ùå The dataset has non-linear relationships (Polynomial Regression or Gradient Boosting may be better).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Real Estate (Realtor, Zillow, Airbnb) ‚Üí Predicting property price based on location, area, and customer rating. E-commerce (Amazon, Flipkart, Shopify) ‚Üí Estimating product demand based on multiple factors like price, rating, seasonality, and location."
      ],
      "metadata": {
        "id": "qkaHFWu-LKNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    'House_ID': [1, 2, 3],\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment'],\n",
        "    'Price': [500000, 750000, 600000],\n",
        "    'Construction_Date': ['2020-01-01', '2018-05-15', '2019-07-20'],\n",
        "    'Is_Active': [np.nan, False, True],\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\"],\n",
        "    'Area': [1200, 1500, 1300],\n",
        "    'Rating': [4, 5, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical feature 'Type' into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
        "\n",
        "# Convert boolean 'Is_Active' to numerical (0/1) and handle NaN values\n",
        "imputer_bool = SimpleImputer(strategy='most_frequent')\n",
        "df['Is_Active'] = imputer_bool.fit_transform(df[['Is_Active']])\n",
        "\n",
        "# Impute missing values in 'Rating' with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Rating'] = imputer.fit_transform(df[['Rating']])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Area', 'Rating', 'Type', 'Is_Active']]\n",
        "y = df['Price']\n",
        "\n",
        "# Train multiple linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict prices based on the given data\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "# Regression equation coefficients\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "\n",
        "# Display results\n",
        "df['Predicted_Price'] = predictions\n",
        "print(f\"Regression Equation: Price = {intercept:.2f} + ({coefficients[0]:.2f} * Area) + ({coefficients[1]:.2f} * Rating) + ({coefficients[2]:.2f} * Type) + ({coefficients[3]:.2f} * Is_Active)\")\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "df[['Price', 'Predicted_Price']]\n"
      ],
      "metadata": {
        "id": "rNlAqv-lLIT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3Ô∏è‚É£ Polynomial Regression\n",
        "üìå Use Case: Add polynomial terms for Area or Rating üìå Best When: ‚úÖ The relationship between Price and Area or Rating is non-linear. ‚úÖ You need a more flexible model than Linear Regression.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå Overfitting risk is high (especially with high-degree polynomials). ‚ùå The dataset is small (adding polynomial terms can increase complexity without benefit).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Stock Market Predictions (Financial Markets) ‚Üí Predicting stock prices based on historical trends. Energy Consumption Forecasting (Utility Companies) ‚Üí Estimating electricity usage based on temperature, time, and past usage patterns."
      ],
      "metadata": {
        "id": "by5QhMp8Lvn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    'House_ID': [1, 2, 3],\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment'],\n",
        "    'Price': [500000, 750000, 600000],\n",
        "    'Construction_Date': ['2020-01-01', '2018-05-15', '2019-07-20'],\n",
        "    'Is_Active': [np.nan, False, True],\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\"],\n",
        "    'Area': [1200, 1500, 1300],\n",
        "    'Rating': [4, 5, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical feature 'Type' into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
        "\n",
        "# Convert boolean 'Is_Active' to numerical (0/1) and handle NaN values\n",
        "imputer_bool = SimpleImputer(strategy='most_frequent')\n",
        "df['Is_Active'] = imputer_bool.fit_transform(df[['Is_Active']])\n",
        "\n",
        "# Impute missing values in 'Rating' with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Rating'] = imputer.fit_transform(df[['Rating']])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Area', 'Rating', 'Type', 'Is_Active']]\n",
        "y = df['Price']\n",
        "\n",
        "# Apply Polynomial Features (degree=2 for quadratic regression)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train Polynomial Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Predict prices based on the given data\n",
        "predictions = model.predict(X_poly)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "# Regression equation coefficients\n",
        "intercept = model.intercept_\n",
        "coefficients = model.coef_\n",
        "feature_names = poly.get_feature_names_out(['Area', 'Rating', 'Type', 'Is_Active'])\n",
        "\n",
        "# Display results\n",
        "df['Predicted_Price'] = predictions\n",
        "print(\"Regression Equation:\")\n",
        "equation = f\"Price = {intercept:.2f}\"\n",
        "for coef, feature in zip(coefficients, feature_names):\n",
        "    equation += f\" + ({coef:.2f} * {feature})\"\n",
        "print(equation)\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "# Plot actual vs predicted prices\n",
        "plt.scatter(y, predictions, color='blue')\n",
        "plt.plot([min(y), max(y)], [min(y), max(y)], linestyle='--', color='red')\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Actual vs Predicted Prices\")\n",
        "plt.show()\n",
        "\n",
        "df[['Price', 'Predicted_Price']]\n"
      ],
      "metadata": {
        "id": "_bXCcaBiLrX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4Ô∏è‚É£ SVM Regression (Support Vector Regression - SVR)\n",
        "---\n",
        "\n",
        "üìå Use Case: Price (target) vs. Area, Rating üìå Best When: ‚úÖ The dataset is small to medium-sized and contains outliers. ‚úÖ You need a robust model that doesn‚Äôt overfit easily.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå The dataset is large (SVM can be computationally expensive). ‚ùå You need a fully interpretable model (SVM is harder to interpret than Linear Regression).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "House Price Estimation (Zillow, Redfin) ‚Üí Predicting home value based on multiple features, handling outliers better than Linear Regression. Healthcare (Medical Diagnosis) ‚Üí Estimating disease risk based on patient symptoms."
      ],
      "metadata": {
        "id": "K1xCbMqCMmsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    'House_ID': [1, 2, 3],\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment'],\n",
        "    'Price': [500000, 750000, 600000],\n",
        "    'Construction_Date': ['2020-01-01', '2018-05-15', '2019-07-20'],\n",
        "    'Is_Active': [np.nan, False, True],\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\"],\n",
        "    'Area': [1200, 1500, 1300],\n",
        "    'Rating': [4, 5, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical feature 'Type' into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
        "\n",
        "# Convert boolean 'Is_Active' to numerical (0/1) and handle NaN values\n",
        "imputer_bool = SimpleImputer(strategy='most_frequent')\n",
        "df['Is_Active'] = imputer_bool.fit_transform(df[['Is_Active']])\n",
        "\n",
        "# Impute missing values in 'Rating' with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Rating'] = imputer.fit_transform(df[['Rating']])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Area', 'Rating', 'Type', 'Is_Active']]\n",
        "y = df['Price']\n",
        "\n",
        "# Standardize features (important for SVR)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Train SVR Model\n",
        "svr_model = SVR(kernel='rbf')  # Using Radial Basis Function kernel\n",
        "svr_model.fit(X_scaled, y_scaled)\n",
        "\n",
        "# Predict prices based on the given data\n",
        "predictions_scaled = svr_model.predict(X_scaled)\n",
        "predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "# Display results\n",
        "df['Predicted_Price'] = predictions\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "# Plot actual vs predicted prices\n",
        "plt.scatter(y, predictions, color='blue')\n",
        "plt.plot([min(y), max(y)], [min(y), max(y)], linestyle='--', color='red')\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Actual vs Predicted Prices (SVR)\")\n",
        "plt.show()\n",
        "\n",
        "df[['Price', 'Predicted_Price']]\n"
      ],
      "metadata": {
        "id": "V7we8hqfMh_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5Ô∏è‚É£ k-NN Regression\n",
        "---\n",
        "\n",
        "\n",
        "üìå Use Case: Price (target) vs. Area, Rating üìå Best When: ‚úÖ The relationship between variables is non-linear. ‚úÖ The dataset is small to medium-sized (k-NN is memory-intensive).\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå The dataset is large (k-NN is slow as it stores all data points and computes distances). ‚ùå There are many irrelevant features (k-NN can be affected by noise).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Recommendation Systems (Netflix, Spotify, Amazon) ‚Üí Suggesting similar movies or products based on past interactions. Predicting Housing Prices (Real Estate) ‚Üí Finding similar properties based on Price, Area, and Rating."
      ],
      "metadata": {
        "id": "_0Q-AIETM9uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    'House_ID': [1, 2, 3],\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment'],\n",
        "    'Price': [500000, 750000, 600000],\n",
        "    'Construction_Date': ['2020-01-01', '2018-05-15', '2019-07-20'],\n",
        "    'Is_Active': [np.nan, False, True],\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\"],\n",
        "    'Area': [1200, 1500, 1300],\n",
        "    'Rating': [4, 5, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical feature 'Type' into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])\n",
        "\n",
        "# Convert boolean 'Is_Active' to numerical (0/1) and handle NaN values\n",
        "imputer_bool = SimpleImputer(strategy='most_frequent')\n",
        "df['Is_Active'] = imputer_bool.fit_transform(df[['Is_Active']])\n",
        "\n",
        "# Impute missing values in 'Rating' with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df['Rating'] = imputer.fit_transform(df[['Rating']])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Area', 'Rating', 'Type', 'Is_Active']]\n",
        "y = df['Price']\n",
        "\n",
        "# Standardize features (important for k-NN)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Train k-NN Regression Model\n",
        "knn_model = KNeighborsRegressor(n_neighbors=2)  # Using 2 nearest neighbors\n",
        "knn_model.fit(X_scaled, y_scaled)\n",
        "\n",
        "# Predict prices based on the given data\n",
        "predictions_scaled = knn_model.predict(X_scaled)\n",
        "predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "# Display results\n",
        "df['Predicted_Price'] = predictions\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "# Plot actual vs predicted prices\n",
        "plt.scatter(y, predictions, color='blue')\n",
        "plt.plot([min(y), max(y)], [min(y), max(y)], linestyle='--', color='red')\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Actual vs Predicted Prices (k-NN Regression)\")\n",
        "plt.show()\n",
        "\n",
        "df[['Price', 'Predicted_Price']]\n"
      ],
      "metadata": {
        "id": "7fRyP0EMM5E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2Ô∏è‚É£ Classification (Categorizing Data)\n",
        "--\n",
        "Algorithm Best For Example Data Data Type Logistic Regression Binary classes Spam vs. Not Spam Categorical (0/1)\n",
        "\n",
        "Multiclass Logistic Regression Multiple categories Classifying plants into species Categorical (3+ classes)\n",
        "\n",
        "Decision Tree Simple, rule-based classification Approving a loan Mixed (Numerical & Categorical)\n",
        "\n",
        "Random Forest More accurate than a single decision tree Fraud Detection Mixed (Numerical & Categorical)\n",
        "\n",
        "Support Vector Machine (SVM) High-dimensional data Handwriting Recognition Continuous, Categorical\n",
        "\n",
        "k-NN Classification Small datasets, local patterns Disease classification based on symptoms Mixed (Numerical & Categorical)"
      ],
      "metadata": {
        "id": "kVy0pXPMdrVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1Ô∏è‚É£ Logistic Regression (Binary Class)\n",
        "---\n",
        "\n",
        "\n",
        "üìå Use Case: Is_Active (target) vs. Price, Area\n",
        "\n",
        "üìå Best When: ‚úÖ Data is linearly separable (clear boundary exists). ‚úÖ You need probability estimates for predictions. ‚úÖ The dataset is not too large.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå Data is non-linear (Logistic Regression struggles with complex decision boundaries). ‚ùå There are too many irrelevant features.\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Customer Churn Prediction (Amazon, Netflix, SaaS platforms) ‚Üí Predicting if a user will stay active or leave. Credit Risk Assessment (Banking & Finance) ‚Üí Determining if a person is a high-risk borrower."
      ],
      "metadata": {
        "id": "7nemzxymUKpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Sample Dataset\n",
        "data = {\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment', 'Villa', 'Apartment', 'Villa'],\n",
        "    'Is_Active': [1, 0, 1, 1, 0, 1],  # Target Variable\n",
        "    'Area': [1200, 1500, 1300, 1600, 1250, 1550],  # Feature\n",
        "    'Rating': [4, 5, 4.5, 3.5, 4.2, 4]  # Feature\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical 'Type' into numerical (0 = Apartment, 1 = Villa)\n",
        "df['Type'] = df['Type'].map({'Apartment': 0, 'Villa': 1})\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df[['Area', 'Rating', 'Type']]\n",
        "y = df['Is_Active']\n",
        "\n",
        "# Split Data into Train & Test Sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale Features (Logistic Regression benefits from scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression Model\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = log_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Plot Decision Boundary (only possible for 2D features)\n",
        "plt.scatter(X_test['Area'], X_test['Rating'], c=y_pred, cmap='coolwarm', edgecolors='k')\n",
        "plt.xlabel(\"Area\")\n",
        "plt.ylabel(\"Rating\")\n",
        "plt.title(\"Logistic Regression Decision Boundary\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vztWuXWsUHFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2Ô∏è‚É£ Multiclass Logistic Regression\n",
        "--\n",
        "üìå Use Case: Type (target) vs. Price, Area, Rating\n",
        "\n",
        "üìå Best When: ‚úÖ Data has multiple classes but remains linearly separable. ‚úÖ Fast predictions are required.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå Data has complex, non-linear relationships. ‚ùå The dataset contains many interdependent features.\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "E-commerce Product Categorization (Amazon, Flipkart) ‚Üí Classifying products as Luxury, Mid-Range, Budget. Property Type Prediction (Real Estate) ‚Üí Classifying a house as Apartment, Villa, Townhouse."
      ],
      "metadata": {
        "id": "IMPdbFZqfm3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Sample Dataset\n",
        "data = {\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment', 'Villa', 'Studio', 'Apartment', 'Studio', 'Villa'],\n",
        "    'Area': [1200, 1500, 1300, 1600, 1000, 1250, 900, 1550],  # Feature\n",
        "    'Rating': [4, 5, 4.5, 3.5, 4.2, 4, 3.8, 4.7],  # Feature\n",
        "    'Is_Active': [1, 0, 1, 1, 0, 1, 0, 1]  # Feature\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical target 'Type' into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])  # (Apartment=0, Studio=1, Villa=2)\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df[['Area', 'Rating', 'Is_Active']]\n",
        "y = df['Type']\n",
        "\n",
        "# Split Data into Train & Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale Features (Logistic Regression benefits from scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Multiclass Logistic Regression Model\n",
        "log_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on Test Data\n",
        "y_pred = log_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Visualizing Predictions\n",
        "plt.scatter(X_test['Area'], X_test['Rating'], c=y_pred, cmap='coolwarm', edgecolors='k')\n",
        "plt.xlabel(\"Area\")\n",
        "plt.ylabel(\"Rating\")\n",
        "plt.title(\"Multiclass Logistic Regression Decision Boundary\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9iRXdI32fpR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3Ô∏è‚É£ Na√Øve Bayes\n",
        "--\n",
        "üìå Use Case: Type (target) vs. Price, Area, Rating\n",
        "\n",
        "üìå Best When: ‚úÖ The dataset is small. ‚úÖ Features are mostly independent. ‚úÖ You need fast model training and predictions.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå Features are highly correlated (e.g., Price and Area are often dependent). ‚ùå Data is non-linear (Na√Øve Bayes assumes simple decision boundaries).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Spam Detection (Facebook, Gmail, Twitter) ‚Üí Classifying emails or comments as Spam, Promotional, or Normal. Quick Prototyping for Classification Models."
      ],
      "metadata": {
        "id": "s5LoZvP0ga76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ‚úÖ 1. Load Previous Dataset\n",
        "data = {\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\", \"Terrible experience.\", \"Loved it!\", \"Would not recommend.\"],\n",
        "    'Sentiment': [1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ‚úÖ 2. Convert Text into TF-IDF Features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Review'])  # Text data converted to numerical form\n",
        "y = df['Sentiment']  # Target variable\n",
        "\n",
        "# ‚úÖ 3. Split Data into Train & Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ‚úÖ 4. Train Na√Øve Bayes Model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ 5. Predict on Test Data\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# ‚úÖ 6. Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ‚úÖ 7. Test with a New Review\n",
        "new_review = [\"The place was amazing and I loved the experience!\"]\n",
        "new_review_vectorized = vectorizer.transform(new_review)\n",
        "prediction = nb_model.predict(new_review_vectorized)\n",
        "print(\"\\nNew Review Sentiment:\", \"Positive\" if prediction[0] == 1 else \"Negative\")\n"
      ],
      "metadata": {
        "id": "VvjKrTwwgU2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4Ô∏è‚É£ Decision Tree\n",
        "--\n",
        "üìå Use Case: Type (target) vs. Price, Area, Rating\n",
        "\n",
        "üìå Best When: ‚úÖ The dataset contains non-linear relationships. ‚úÖ You need interpretability (can visualize decision paths). ‚úÖ There are missing values in the dataset.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå The dataset is small (trees tend to overfit small datasets). ‚ùå You need high accuracy (Random Forest performs better).\n",
        "\n",
        "üîß Industry Applications: Loan Approval (Banking, FinTech) ‚Üí Deciding whether a person gets Loan Approved, Partially Approved, or Denied. Medical Diagnosis (Healthcare AI) ‚Üí Classifying patients into Low-Risk, Medium-Risk, High-Risk categories."
      ],
      "metadata": {
        "id": "vcgR84BkiAS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ‚úÖ 1. Load Dataset\n",
        "data = {\n",
        "    'Type': ['Apartment', 'Villa', 'Apartment', 'Villa', 'Studio', 'Apartment', 'Studio', 'Villa'],\n",
        "    'Area': [1200, 1500, 1300, 1600, 1000, 1250, 900, 1550],  # Feature\n",
        "    'Rating': [4, 5, 4.5, 3.5, 4.2, 4, 3.8, 4.7],  # Feature\n",
        "    'Is_Active': [1, 0, 1, 1, 0, 1, 0, 1]  # Feature\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ‚úÖ 2. Convert Target Variable 'Type' into Numerical Labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Type'] = label_encoder.fit_transform(df['Type'])  # (Apartment=0, Studio=1, Villa=2)\n",
        "\n",
        "# ‚úÖ 3. Define Features (X) and Target (y)\n",
        "X = df[['Area', 'Rating', 'Is_Active']]\n",
        "y = df['Type']\n",
        "\n",
        "# ‚úÖ 4. Split Data into Train & Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ 5. Train Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ 6. Predict on Test Data\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# ‚úÖ 7. Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ‚úÖ 8. Visualize Decision Tree\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_tree(dt_model, feature_names=['Area', 'Rating', 'Is_Active'], class_names=label_encoder.classes_, filled=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MLctmN9HiDw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5Ô∏è‚É£ k-NN Classification\n",
        "--\n",
        "üìå Use Case: Type (target) vs. Price, Area, Rating\n",
        "\n",
        "üìå Best When: ‚úÖ The dataset is small (k-NN is memory-intensive). ‚úÖ Relationships in data are non-linear. ‚úÖ You don‚Äôt need to train a model, just store data and classify new points.\n",
        "\n",
        "‚ö†Ô∏è Avoid When: ‚ùå The dataset is large (k-NN is slow in predictions). ‚ùå You have many features (suffers from the \"Curse of Dimensionality\").\n",
        "\n",
        "üîß Industry Applications: Facebook Friend Recommendation ‚Üí Suggesting new connections based on similar interests, location, interactions. Handwriting Recognition (OCR Systems) ‚Üí Classifying handwritten letters/numbers."
      ],
      "metadata": {
        "id": "IJGR6qKMhjhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ‚úÖ 1. Load Previous Dataset\n",
        "data = {\n",
        "    'Review': [\"Great place!\", \"Not worth it.\", \"Highly recommended.\", \"Terrible experience.\", \"Loved it!\", \"Would not recommend.\"],\n",
        "    'Sentiment': [1, 0, 1, 0, 1, 0]  # 1 = Positive, 0 = Negative\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ‚úÖ 2. Convert Text into TF-IDF Features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Review'])  # Convert text to numerical form\n",
        "y = df['Sentiment']  # Target variable\n",
        "\n",
        "# ‚úÖ 3. Split Data into Train & Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ‚úÖ 4. Train k-NN Classifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)  # k=3 (You can tune this)\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ 5. Predict on Test Data\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# ‚úÖ 6. Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ‚úÖ 7. Test with a New Review\n",
        "new_review = [\"The place was amazing and I loved the experience!\"]\n",
        "new_review_vectorized = vectorizer.transform(new_review)\n",
        "prediction = knn_model.predict(new_review_vectorized)\n",
        "print(\"\\nNew Review Sentiment:\", \"Positive\" if prediction[0] == 1 else \"Negative\")\n"
      ],
      "metadata": {
        "id": "2xAb63vOhd0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fOVuOnh-gUST"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogbJeRXNcJV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP"
      ],
      "metadata": {
        "id": "icRmI11TKVJF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1Ô∏è‚É£ Count Vectorization (Bag-of-Words Model)\n",
        "---\n",
        "\n",
        "\n",
        "üìå Use Case: Convert text into a numerical feature matrix.\n",
        "üìå Best When:\n",
        "‚úÖ You need a fast and simple way to represent text numerically.\n",
        "‚úÖ You are working with structured text data (e.g., emails, customer reviews).\n",
        "\n",
        "‚ö†Ô∏è Avoid When:\n",
        "‚ùå You need semantic understanding (BoW ignores meaning).\n",
        "‚ùå The dataset has complex word relationships (use word embeddings instead).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "Spam Detection (Gmail, Yahoo Mail, Outlook) ‚Üí Representing emails for classification.\n",
        "News Categorization (Google News, Bloomberg AI) ‚Üí Grouping articles into Politics, Sports, Tech.\n",
        "üõ† Scikit-Learn Example:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\"This is a great product!\", \"I hate this product!\", \"This is amazing.\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())\n",
        "2Ô∏è‚É£ TF-IDF (Term Frequency - Inverse Document Frequency)\n",
        "---\n",
        "üìå Use Case: Weight words based on importance in documents.\n",
        "üìå Best When:\n",
        "‚úÖ You need to filter out common words and emphasize important terms.\n",
        "‚úÖ You are working with text classification tasks (e.g., sentiment analysis, spam detection).\n",
        "\n",
        "‚ö†Ô∏è Avoid When:\n",
        "‚ùå You need deep semantic understanding of text.\n",
        "‚ùå The dataset is small (TF-IDF works best on larger datasets).\n",
        "\n",
        "üîß Industry Applications:\n",
        "\n",
        "SEO Optimization (Google, Bing, Ahrefs) ‚Üí Keyword relevance analysis in search engine ranking.\n",
        "Customer Feedback Analysis (Amazon, Netflix, TripAdvisor) ‚Üí Identifying important words in reviews."
      ],
      "metadata": {
        "id": "jAgcHDiIPHj7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qYNklE-lh4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}